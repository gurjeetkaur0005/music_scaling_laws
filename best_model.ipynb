{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyMiHAF57BBolJ8cv4be5Zw8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os, json, time, math\n","import numpy as np\n","\n","if not os.path.exists('/content/drive/MyDrive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Google Drive already mounted\")\n","\n","DATA_DIR = \"/content/drive/MyDrive/tokenized_subset\"\n","BIN_DIR  = os.path.join(DATA_DIR, \"bin\")\n","\n","TRAIN_BIN = os.path.join(BIN_DIR, \"train.bin\")\n","VAL_BIN   = os.path.join(BIN_DIR, \"val.bin\")\n","VOCAB_JSON = os.path.join(DATA_DIR, \"vocab.json\")\n","TEST_BIN = os.path.join(BIN_DIR, \"test.bin\")\n","assert os.path.exists(TRAIN_BIN), f\"Missing {TRAIN_BIN}\"\n","assert os.path.exists(VAL_BIN), f\"Missing {VAL_BIN}\"\n","assert os.path.exists(VOCAB_JSON), f\"Missing {VOCAB_JSON}\"\n","\n","print(\"Found:\", TRAIN_BIN, VAL_BIN, VOCAB_JSON)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l29xXoVCWXcv","executionInfo":{"status":"ok","timestamp":1765855419223,"user_tz":300,"elapsed":20,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"141852ce-7830-4cb1-bca7-22f33dae0df8"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Google Drive already mounted\n","Found: /content/drive/MyDrive/tokenized_subset/bin/train.bin /content/drive/MyDrive/tokenized_subset/bin/val.bin /content/drive/MyDrive/tokenized_subset/vocab.json\n"]}]},{"cell_type":"code","source":["with open(VOCAB_JSON, \"r\") as f:\n","    vocab = json.load(f)\n","\n","if all(isinstance(v, int) for v in vocab.values()):\n","    token_to_id = vocab\n","    id_to_token = {i: t for t, i in token_to_id.items()}\n","else:\n","\n","    id_to_token = {int(k): v for k, v in vocab.items()}\n","    token_to_id = {v: k for k, v in id_to_token.items()}\n","\n","vocab_size = len(id_to_token)\n","print(\"Vocab size:\", vocab_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFAMyGDRWYCn","executionInfo":{"status":"ok","timestamp":1765841414972,"user_tz":300,"elapsed":8,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"12da23e7-cebc-42c4-91a9-66c06c5c3066"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 1734\n"]}]},{"cell_type":"code","source":["import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", device)\n","\n","class BinDataset:\n","    def __init__(self, path, block_size):\n","        self.data = np.memmap(path, dtype=np.uint32, mode='r')\n","        self.block_size = block_size\n","\n","    def get_batch(self, batch_size, device):\n","        ix = torch.randint(len(self.data) - self.block_size - 1, (batch_size,))\n","        x = torch.stack([\n","            torch.from_numpy(self.data[i:i+self.block_size].astype(np.int64))\n","            for i in ix\n","        ])\n","        y = torch.stack([\n","            torch.from_numpy(self.data[i+1:i+self.block_size+1].astype(np.int64))\n","            for i in ix\n","        ])\n","        return x.to(device), y.to(device)\n","\n","block_size = 256\n","train_data = BinDataset(TRAIN_BIN, block_size)\n","val_data   = BinDataset(VAL_BIN, block_size)\n","\n","total_train_tokens = len(train_data.data)\n","print(\"Total train tokens:\", total_train_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-bx_biQWbMH","executionInfo":{"status":"ok","timestamp":1765841426218,"user_tz":300,"elapsed":55,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"2afd0115-d4f0-4d0c-ede3-1371551cae2c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Total train tokens: 140459152\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, n_embd, n_head, block_size, attn_dropout=0.1, resid_dropout=0.1):\n","        super().__init__()\n","        assert n_embd % n_head == 0\n","        self.n_head = n_head\n","        self.head_dim = n_embd // n_head\n","\n","        self.key   = nn.Linear(n_embd, n_embd, bias=False)\n","        self.query = nn.Linear(n_embd, n_embd, bias=False)\n","        self.value = nn.Linear(n_embd, n_embd, bias=False)\n","        self.proj  = nn.Linear(n_embd, n_embd, bias=False)\n","\n","        self.attn_drop = nn.Dropout(attn_dropout)\n","        self.resid_drop = nn.Dropout(resid_dropout)\n","\n","        self.register_buffer(\"mask\", torch.tril(torch.ones(block_size, block_size)))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","\n","        k = self.key(x).view(B, T, self.n_head, self.head_dim).transpose(1,2)\n","        q = self.query(x).view(B, T, self.n_head, self.head_dim).transpose(1,2)\n","        v = self.value(x).view(B, T, self.n_head, self.head_dim).transpose(1,2)\n","\n","        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n","        att = att.masked_fill(self.mask[:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_drop(att)\n","\n","        y = att @ v\n","        y = y.transpose(1,2).contiguous().view(B, T, C)\n","        y = self.proj(y)\n","        y = self.resid_drop(y)\n","        return y\n","\n","class Block(nn.Module):\n","    def __init__(self, n_embd, n_head, block_size, dropout=0.1):\n","        super().__init__()\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.attn = CausalSelfAttention(n_embd, n_head, block_size, attn_dropout=dropout, resid_dropout=dropout)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(n_embd, 4*n_embd),\n","            nn.GELU(),\n","            nn.Linear(4*n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.ln1(x))\n","        x = x + self.mlp(self.ln2(x))\n","        return x\n","\n","class TransformerLM(nn.Module):\n","    def __init__(self, vocab_size, n_layer, n_head, n_embd, block_size, dropout=0.1):\n","        super().__init__()\n","        self.block_size = block_size\n","        self.tok_emb = nn.Embedding(vocab_size, n_embd)\n","        self.pos_emb = nn.Parameter(torch.zeros(1, block_size, n_embd))\n","        self.drop = nn.Dropout(dropout)\n","        self.blocks = nn.ModuleList([Block(n_embd, n_head, block_size, dropout=dropout) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm(n_embd)\n","        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n","\n","        nn.init.normal_(self.pos_emb, mean=0.0, std=0.02)\n","\n","    def forward(self, x, targets=None):\n","        B, T = x.size()\n","        assert T <= self.block_size\n","        x = self.tok_emb(x) + self.pos_emb[:, :T]\n","        x = self.drop(x)\n","        for blk in self.blocks:\n","            x = blk(x)\n","        x = self.ln_f(x)\n","        logits = self.head(x)\n","\n","        loss = None\n","        if targets is not None:\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n","        return logits, loss\n","\n","def count_params_M(model):\n","    return sum(p.numel() for p in model.parameters()) / 1e6\n","\n","@torch.no_grad()\n","def estimate_val_loss(model, data, batch_size, iters=200):\n","    model.eval()\n","    losses = []\n","    for _ in range(iters):\n","        xb, yb = data.get_batch(batch_size, device)\n","        _, loss = model(xb, yb)\n","        losses.append(loss.item())\n","    model.train()\n","    return sum(losses) / len(losses)\n"],"metadata":{"id":"CYXEmtzfWeAV","executionInfo":{"status":"ok","timestamp":1765841438135,"user_tz":300,"elapsed":6,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","def save_ckpt(path, model, opt, step, tokens_seen, best_val):\n","    ckpt = {\n","        \"model\": model.state_dict(),\n","        \"opt\": opt.state_dict(),\n","        \"step\": step,\n","        \"tokens_seen\": tokens_seen,\n","        \"best_val\": best_val,\n","    }\n","    torch.save(ckpt, path)\n","\n","def load_ckpt(path, model, opt=None):\n","    ckpt = torch.load(path, map_location=\"cpu\")\n","    model.load_state_dict(ckpt[\"model\"])\n","    if opt is not None and \"opt\" in ckpt:\n","        opt.load_state_dict(ckpt[\"opt\"])\n","    return ckpt\n","\n","def train_best_model_time_budget(\n","    cfg,\n","    train_data,\n","    val_data,\n","    time_budget_min=120,\n","    batch_size=8,\n","    grad_accum_steps=4,\n","    lr=3e-4,\n","    min_lr=3e-5,\n","    weight_decay=0.1,\n","    grad_clip=1.0,\n","    warmup_frac=0.02,\n","    eval_every=5000,\n","    val_iters=200,\n","    ckpt_dir=\"/content/drive/MyDrive/best_model_part4\",\n","    ckpt_name=\"best_transformer.pt\",\n","    resume=True,\n","    use_compile=True\n","):\n","    os.makedirs(ckpt_dir, exist_ok=True)\n","    ckpt_path = os.path.join(ckpt_dir, ckpt_name)\n","    last_path = os.path.join(ckpt_dir, \"last.pt\")\n","\n","    model = TransformerLM(**cfg).to(device)\n","    print(\"Params (M):\", count_params_M(model))\n","\n","    opt = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=weight_decay)\n","\n","\n","    scaler = torch.amp.GradScaler('cuda', enabled=(device == \"cuda\"))\n","\n","\n","    step = 0\n","    tokens_seen = 0\n","    best_val = float(\"inf\")\n","    if resume and os.path.exists(last_path):\n","        ck = load_ckpt(last_path, model, opt)\n","        step = ck.get(\"step\", 0)\n","        tokens_seen = ck.get(\"tokens_seen\", 0)\n","        best_val = ck.get(\"best_val\", best_val)\n","        print(f\"Resumed from {last_path} | step={step} tokens_seen={tokens_seen} best_val={best_val:.4f}\")\n","\n","    if use_compile:\n","        try:\n","            model = torch.compile(model)\n","            print(\"torch.compile enabled âœ…\")\n","        except Exception as e:\n","            print(\"torch.compile failed (continuing without):\", e)\n","\n","\n","    warmup_steps = max(10, int(warmup_frac * 200000))\n","    def get_lr(s):\n","        if s < warmup_steps:\n","            return lr * (s / warmup_steps)\n","\n","        progress = (s - warmup_steps) / max(1, (200000 - warmup_steps))\n","        progress = min(1.0, progress)\n","        return max(min_lr, lr * 0.5 * (1.0 + math.cos(math.pi * progress)))\n","\n","    tokens_per_step = batch_size * cfg[\"block_size\"] * grad_accum_steps\n","    print(\"Tokens/optimizer-step:\", tokens_per_step)\n","\n","    torch.cuda.reset_peak_memory_stats()\n","    t0 = time.time()\n","    deadline = t0 + time_budget_min * 60\n","\n","    model.train()\n","    loss_ema = None\n","    ema_beta = 0.95\n","\n","    while time.time() < deadline:\n","        lr_now = get_lr(step)\n","        for pg in opt.param_groups:\n","            pg[\"lr\"] = lr_now\n","\n","        opt.zero_grad(set_to_none=True)\n","\n","        total_loss = 0.0\n","        for micro in range(grad_accum_steps):\n","            xb, yb = train_data.get_batch(batch_size, device)\n","            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device==\"cuda\")):\n","                _, loss = model(xb, yb)\n","                loss = loss / grad_accum_steps\n","            scaler.scale(loss).backward()\n","            total_loss += loss.item()\n","\n","        scaler.unscale_(opt)\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","        scaler.step(opt)\n","        scaler.update()\n","\n","        tokens_seen += tokens_per_step\n","        loss_val = total_loss\n","        loss_ema = loss_val if loss_ema is None else (ema_beta * loss_ema + (1-ema_beta) * loss_val)\n","\n","        if step % 200 == 0:\n","            elapsed = (time.time() - t0) / 60\n","            peak = torch.cuda.max_memory_allocated() / 1024**2 if device==\"cuda\" else 0\n","            print(f\"step {step} | lr {lr_now:.2e} | loss_ema {loss_ema:.4f} | tokens {tokens_seen:,} | {elapsed:.1f} min | peak {peak:.0f} MB\")\n","\n","\n","        if step > 0 and step % eval_every == 0:\n","            val_loss = estimate_val_loss(model, val_data, batch_size=batch_size, iters=val_iters)\n","            print(f\"âœ… eval @ step {step}: val_loss={val_loss:.4f} (best={best_val:.4f})\")\n","\n","            save_ckpt(last_path, model, opt, step, tokens_seen, best_val)\n","\n","            if val_loss < best_val:\n","                best_val = val_loss\n","                save_ckpt(ckpt_path, model, opt, step, tokens_seen, best_val)\n","                print(f\"ðŸ† New best saved to: {ckpt_path}\")\n","\n","        step += 1\n","\n","\n","    save_ckpt(last_path, model, opt, step, tokens_seen, best_val)\n","    print(\"Finished. Saved last checkpoint to:\", last_path)\n","\n","    peak = torch.cuda.max_memory_allocated() / 1024**2 if device==\"cuda\" else 0\n","    return model, {\"step\": step, \"tokens_seen\": tokens_seen, \"best_val\": best_val, \"peak_mem_MB\": peak, \"best_ckpt\": ckpt_path, \"last_ckpt\": last_path}\n"],"metadata":{"id":"EJl7i61wWggb","executionInfo":{"status":"ok","timestamp":1765841446354,"user_tz":300,"elapsed":16,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["best_cfg = dict(\n","    vocab_size=vocab_size,\n","    n_layer=20,\n","    n_head=20,\n","    n_embd=640,\n","    block_size=256,\n","    dropout=0.1,\n",")\n","\n","time_budget_min = 120\n","\n","model, stats = train_best_model_time_budget(\n","    best_cfg,\n","    train_data,\n","    val_data,\n","    time_budget_min=time_budget_min,\n","    batch_size=8,\n","    grad_accum_steps=4,\n","    lr=3e-4,\n","    min_lr=3e-5,\n","    weight_decay=0.1,\n","    eval_every=2000,\n","    val_iters=200,\n","    ckpt_dir=\"/content/drive/MyDrive/best_model_part4\",\n","    ckpt_name=\"best_transformer.pt\",\n","    resume=True,\n","    use_compile=True\n",")\n","\n","print(\"Training stats:\", stats)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qjPI2VQhWig7","executionInfo":{"status":"ok","timestamp":1765848660478,"user_tz":300,"elapsed":7203800,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"516cd60f-44b6-47e6-9798-ca384de30658"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Params (M): 100.80384\n","torch.compile enabled âœ…\n","Tokens/optimizer-step: 8192\n","step 0 | lr 0.00e+00 | loss_ema 7.7350 | tokens 8,192 | 0.8 min | peak 7743 MB\n","step 200 | lr 1.50e-05 | loss_ema 3.3434 | tokens 1,646,592 | 1.3 min | peak 8522 MB\n","step 400 | lr 3.00e-05 | loss_ema 2.6267 | tokens 3,284,992 | 1.8 min | peak 8522 MB\n","step 600 | lr 4.50e-05 | loss_ema 2.4015 | tokens 4,923,392 | 2.3 min | peak 8522 MB\n","step 800 | lr 6.00e-05 | loss_ema 2.2934 | tokens 6,561,792 | 2.8 min | peak 8522 MB\n","step 1000 | lr 7.50e-05 | loss_ema 2.1609 | tokens 8,200,192 | 3.3 min | peak 8522 MB\n","step 1200 | lr 9.00e-05 | loss_ema 2.0473 | tokens 9,838,592 | 3.8 min | peak 8522 MB\n","step 1400 | lr 1.05e-04 | loss_ema 1.9509 | tokens 11,476,992 | 4.3 min | peak 8522 MB\n","step 1600 | lr 1.20e-04 | loss_ema 1.8961 | tokens 13,115,392 | 4.8 min | peak 8522 MB\n","step 1800 | lr 1.35e-04 | loss_ema 1.8407 | tokens 14,753,792 | 5.3 min | peak 8522 MB\n","step 2000 | lr 1.50e-04 | loss_ema 1.8254 | tokens 16,392,192 | 5.8 min | peak 8522 MB\n","âœ… eval @ step 2000: val_loss=2.6705 (best=inf)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 2200 | lr 1.65e-04 | loss_ema 1.6991 | tokens 18,030,592 | 6.9 min | peak 8522 MB\n","step 2400 | lr 1.80e-04 | loss_ema 1.6272 | tokens 19,668,992 | 7.4 min | peak 8522 MB\n","step 2600 | lr 1.95e-04 | loss_ema 1.5694 | tokens 21,307,392 | 7.9 min | peak 8522 MB\n","step 2800 | lr 2.10e-04 | loss_ema 1.5251 | tokens 22,945,792 | 8.4 min | peak 8522 MB\n","step 3000 | lr 2.25e-04 | loss_ema 1.4522 | tokens 24,584,192 | 8.9 min | peak 8522 MB\n","step 3200 | lr 2.40e-04 | loss_ema 1.3926 | tokens 26,222,592 | 9.4 min | peak 8522 MB\n","step 3400 | lr 2.55e-04 | loss_ema 1.3556 | tokens 27,860,992 | 9.9 min | peak 8522 MB\n","step 3600 | lr 2.70e-04 | loss_ema 1.3307 | tokens 29,499,392 | 10.4 min | peak 8522 MB\n","step 3800 | lr 2.85e-04 | loss_ema 1.3235 | tokens 31,137,792 | 10.9 min | peak 8522 MB\n","step 4000 | lr 3.00e-04 | loss_ema 1.2813 | tokens 32,776,192 | 11.4 min | peak 8522 MB\n","âœ… eval @ step 4000: val_loss=2.4706 (best=2.6705)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 4200 | lr 3.00e-04 | loss_ema 1.2861 | tokens 34,414,592 | 12.1 min | peak 8522 MB\n","step 4400 | lr 3.00e-04 | loss_ema 1.2900 | tokens 36,052,992 | 12.6 min | peak 8522 MB\n","step 4600 | lr 3.00e-04 | loss_ema 1.2411 | tokens 37,691,392 | 13.1 min | peak 8522 MB\n","step 4800 | lr 3.00e-04 | loss_ema 1.2885 | tokens 39,329,792 | 13.6 min | peak 8522 MB\n","step 5000 | lr 3.00e-04 | loss_ema 1.2481 | tokens 40,968,192 | 14.1 min | peak 8522 MB\n","step 5200 | lr 3.00e-04 | loss_ema 1.2442 | tokens 42,606,592 | 14.6 min | peak 8522 MB\n","step 5400 | lr 3.00e-04 | loss_ema 1.2380 | tokens 44,244,992 | 15.1 min | peak 8522 MB\n","step 5600 | lr 3.00e-04 | loss_ema 1.2295 | tokens 45,883,392 | 15.6 min | peak 8522 MB\n","step 5800 | lr 3.00e-04 | loss_ema 1.2073 | tokens 47,521,792 | 16.1 min | peak 8522 MB\n","step 6000 | lr 3.00e-04 | loss_ema 1.1602 | tokens 49,160,192 | 16.6 min | peak 8522 MB\n","âœ… eval @ step 6000: val_loss=2.3855 (best=2.4706)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 6200 | lr 3.00e-04 | loss_ema 1.1608 | tokens 50,798,592 | 17.4 min | peak 8522 MB\n","step 6400 | lr 3.00e-04 | loss_ema 1.1561 | tokens 52,436,992 | 17.9 min | peak 8522 MB\n","step 6600 | lr 3.00e-04 | loss_ema 1.1527 | tokens 54,075,392 | 18.4 min | peak 8522 MB\n","step 6800 | lr 3.00e-04 | loss_ema 1.1578 | tokens 55,713,792 | 18.9 min | peak 8522 MB\n","step 7000 | lr 3.00e-04 | loss_ema 1.1874 | tokens 57,352,192 | 19.4 min | peak 8522 MB\n","step 7200 | lr 3.00e-04 | loss_ema 1.1508 | tokens 58,990,592 | 19.9 min | peak 8522 MB\n","step 7400 | lr 3.00e-04 | loss_ema 1.1448 | tokens 60,628,992 | 20.4 min | peak 8522 MB\n","step 7600 | lr 3.00e-04 | loss_ema 1.1819 | tokens 62,267,392 | 20.9 min | peak 8522 MB\n","step 7800 | lr 3.00e-04 | loss_ema 1.1835 | tokens 63,905,792 | 21.4 min | peak 8522 MB\n","step 8000 | lr 3.00e-04 | loss_ema 1.1570 | tokens 65,544,192 | 21.9 min | peak 8522 MB\n","âœ… eval @ step 8000: val_loss=2.3496 (best=2.3855)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 8200 | lr 3.00e-04 | loss_ema 1.1607 | tokens 67,182,592 | 22.6 min | peak 8522 MB\n","step 8400 | lr 3.00e-04 | loss_ema 1.1506 | tokens 68,820,992 | 23.1 min | peak 8522 MB\n","step 8600 | lr 3.00e-04 | loss_ema 1.1367 | tokens 70,459,392 | 23.6 min | peak 8522 MB\n","step 8800 | lr 3.00e-04 | loss_ema 1.1306 | tokens 72,097,792 | 24.2 min | peak 8522 MB\n","step 9000 | lr 3.00e-04 | loss_ema 1.1521 | tokens 73,736,192 | 24.7 min | peak 8522 MB\n","step 9200 | lr 2.99e-04 | loss_ema 1.1294 | tokens 75,374,592 | 25.2 min | peak 8522 MB\n","step 9400 | lr 2.99e-04 | loss_ema 1.1246 | tokens 77,012,992 | 25.7 min | peak 8522 MB\n","step 9600 | lr 2.99e-04 | loss_ema 1.1308 | tokens 78,651,392 | 26.2 min | peak 8522 MB\n","step 9800 | lr 2.99e-04 | loss_ema 1.1256 | tokens 80,289,792 | 26.7 min | peak 8522 MB\n","step 10000 | lr 2.99e-04 | loss_ema 1.1001 | tokens 81,928,192 | 27.2 min | peak 8522 MB\n","âœ… eval @ step 10000: val_loss=2.3175 (best=2.3496)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 10200 | lr 2.99e-04 | loss_ema 1.1515 | tokens 83,566,592 | 27.9 min | peak 8522 MB\n","step 10400 | lr 2.99e-04 | loss_ema 1.1399 | tokens 85,204,992 | 28.4 min | peak 8522 MB\n","step 10600 | lr 2.99e-04 | loss_ema 1.1092 | tokens 86,843,392 | 28.9 min | peak 8522 MB\n","step 10800 | lr 2.99e-04 | loss_ema 1.1128 | tokens 88,481,792 | 29.4 min | peak 8522 MB\n","step 11000 | lr 2.99e-04 | loss_ema 1.1276 | tokens 90,120,192 | 29.9 min | peak 8522 MB\n","step 11200 | lr 2.99e-04 | loss_ema 1.0912 | tokens 91,758,592 | 30.4 min | peak 8522 MB\n","step 11400 | lr 2.99e-04 | loss_ema 1.1499 | tokens 93,396,992 | 30.9 min | peak 8522 MB\n","step 11600 | lr 2.99e-04 | loss_ema 1.0967 | tokens 95,035,392 | 31.4 min | peak 8522 MB\n","step 11800 | lr 2.99e-04 | loss_ema 1.0968 | tokens 96,673,792 | 31.9 min | peak 8522 MB\n","step 12000 | lr 2.99e-04 | loss_ema 1.1179 | tokens 98,312,192 | 32.4 min | peak 8522 MB\n","âœ… eval @ step 12000: val_loss=2.3062 (best=2.3175)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 12200 | lr 2.99e-04 | loss_ema 1.1178 | tokens 99,950,592 | 33.1 min | peak 8522 MB\n","step 12400 | lr 2.99e-04 | loss_ema 1.1345 | tokens 101,588,992 | 33.7 min | peak 8522 MB\n","step 12600 | lr 2.99e-04 | loss_ema 1.1491 | tokens 103,227,392 | 34.2 min | peak 8522 MB\n","step 12800 | lr 2.99e-04 | loss_ema 1.1040 | tokens 104,865,792 | 34.7 min | peak 8522 MB\n","step 13000 | lr 2.98e-04 | loss_ema 1.0844 | tokens 106,504,192 | 35.2 min | peak 8522 MB\n","step 13200 | lr 2.98e-04 | loss_ema 1.0886 | tokens 108,142,592 | 35.7 min | peak 8522 MB\n","step 13400 | lr 2.98e-04 | loss_ema 1.0713 | tokens 109,780,992 | 36.2 min | peak 8522 MB\n","step 13600 | lr 2.98e-04 | loss_ema 1.1087 | tokens 111,419,392 | 36.7 min | peak 8522 MB\n","step 13800 | lr 2.98e-04 | loss_ema 1.0884 | tokens 113,057,792 | 37.2 min | peak 8522 MB\n","step 14000 | lr 2.98e-04 | loss_ema 1.0390 | tokens 114,696,192 | 37.7 min | peak 8522 MB\n","âœ… eval @ step 14000: val_loss=2.2934 (best=2.3062)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 14200 | lr 2.98e-04 | loss_ema 1.1005 | tokens 116,334,592 | 38.5 min | peak 8522 MB\n","step 14400 | lr 2.98e-04 | loss_ema 1.0917 | tokens 117,972,992 | 39.0 min | peak 8522 MB\n","step 14600 | lr 2.98e-04 | loss_ema 1.0701 | tokens 119,611,392 | 39.5 min | peak 8522 MB\n","step 14800 | lr 2.98e-04 | loss_ema 1.0683 | tokens 121,249,792 | 40.0 min | peak 8522 MB\n","step 15000 | lr 2.98e-04 | loss_ema 1.0781 | tokens 122,888,192 | 40.5 min | peak 8522 MB\n","step 15200 | lr 2.98e-04 | loss_ema 1.0738 | tokens 124,526,592 | 41.0 min | peak 8522 MB\n","step 15400 | lr 2.98e-04 | loss_ema 1.0536 | tokens 126,164,992 | 41.5 min | peak 8522 MB\n","step 15600 | lr 2.97e-04 | loss_ema 1.0556 | tokens 127,803,392 | 42.0 min | peak 8522 MB\n","step 15800 | lr 2.97e-04 | loss_ema 1.0687 | tokens 129,441,792 | 42.5 min | peak 8522 MB\n","step 16000 | lr 2.97e-04 | loss_ema 1.0606 | tokens 131,080,192 | 43.0 min | peak 8522 MB\n","âœ… eval @ step 16000: val_loss=2.2693 (best=2.2934)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 16200 | lr 2.97e-04 | loss_ema 1.0850 | tokens 132,718,592 | 43.7 min | peak 8522 MB\n","step 16400 | lr 2.97e-04 | loss_ema 1.0648 | tokens 134,356,992 | 44.2 min | peak 8522 MB\n","step 16600 | lr 2.97e-04 | loss_ema 1.0720 | tokens 135,995,392 | 44.8 min | peak 8522 MB\n","step 16800 | lr 2.97e-04 | loss_ema 1.0707 | tokens 137,633,792 | 45.3 min | peak 8522 MB\n","step 17000 | lr 2.97e-04 | loss_ema 1.0579 | tokens 139,272,192 | 45.8 min | peak 8522 MB\n","step 17200 | lr 2.97e-04 | loss_ema 1.0543 | tokens 140,910,592 | 46.3 min | peak 8522 MB\n","step 17400 | lr 2.97e-04 | loss_ema 1.0370 | tokens 142,548,992 | 46.8 min | peak 8522 MB\n","step 17600 | lr 2.96e-04 | loss_ema 1.0509 | tokens 144,187,392 | 47.3 min | peak 8522 MB\n","step 17800 | lr 2.96e-04 | loss_ema 1.0792 | tokens 145,825,792 | 47.8 min | peak 8522 MB\n","step 18000 | lr 2.96e-04 | loss_ema 1.0525 | tokens 147,464,192 | 48.3 min | peak 8522 MB\n","âœ… eval @ step 18000: val_loss=2.2552 (best=2.2693)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 18200 | lr 2.96e-04 | loss_ema 1.0495 | tokens 149,102,592 | 49.1 min | peak 8522 MB\n","step 18400 | lr 2.96e-04 | loss_ema 1.0576 | tokens 150,740,992 | 49.6 min | peak 8522 MB\n","step 18600 | lr 2.96e-04 | loss_ema 1.0634 | tokens 152,379,392 | 50.1 min | peak 8522 MB\n","step 18800 | lr 2.96e-04 | loss_ema 1.0452 | tokens 154,017,792 | 50.6 min | peak 8522 MB\n","step 19000 | lr 2.96e-04 | loss_ema 1.0460 | tokens 155,656,192 | 51.1 min | peak 8522 MB\n","step 19200 | lr 2.96e-04 | loss_ema 1.0757 | tokens 157,294,592 | 51.6 min | peak 8522 MB\n","step 19400 | lr 2.95e-04 | loss_ema 1.0434 | tokens 158,932,992 | 52.1 min | peak 8522 MB\n","step 19600 | lr 2.95e-04 | loss_ema 1.0410 | tokens 160,571,392 | 52.6 min | peak 8522 MB\n","step 19800 | lr 2.95e-04 | loss_ema 1.0697 | tokens 162,209,792 | 53.2 min | peak 8522 MB\n","step 20000 | lr 2.95e-04 | loss_ema 1.0258 | tokens 163,848,192 | 53.6 min | peak 8522 MB\n","âœ… eval @ step 20000: val_loss=2.2507 (best=2.2552)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 20200 | lr 2.95e-04 | loss_ema 1.0672 | tokens 165,486,592 | 54.4 min | peak 8522 MB\n","step 20400 | lr 2.95e-04 | loss_ema 1.0549 | tokens 167,124,992 | 54.9 min | peak 8522 MB\n","step 20600 | lr 2.95e-04 | loss_ema 1.0354 | tokens 168,763,392 | 55.4 min | peak 8522 MB\n","step 20800 | lr 2.95e-04 | loss_ema 1.0570 | tokens 170,401,792 | 55.9 min | peak 8522 MB\n","step 21000 | lr 2.94e-04 | loss_ema 1.0550 | tokens 172,040,192 | 56.4 min | peak 8522 MB\n","step 21200 | lr 2.94e-04 | loss_ema 1.0350 | tokens 173,678,592 | 56.9 min | peak 8522 MB\n","step 21400 | lr 2.94e-04 | loss_ema 1.0542 | tokens 175,316,992 | 57.4 min | peak 8522 MB\n","step 21600 | lr 2.94e-04 | loss_ema 1.0433 | tokens 176,955,392 | 57.9 min | peak 8522 MB\n","step 21800 | lr 2.94e-04 | loss_ema 1.0436 | tokens 178,593,792 | 58.4 min | peak 8522 MB\n","step 22000 | lr 2.94e-04 | loss_ema 1.0291 | tokens 180,232,192 | 58.9 min | peak 8522 MB\n","âœ… eval @ step 22000: val_loss=2.2623 (best=2.2507)\n","step 22200 | lr 2.94e-04 | loss_ema 1.0497 | tokens 181,870,592 | 59.6 min | peak 8522 MB\n","step 22400 | lr 2.94e-04 | loss_ema 1.0619 | tokens 183,508,992 | 60.1 min | peak 8522 MB\n","step 22600 | lr 2.93e-04 | loss_ema 1.0528 | tokens 185,147,392 | 60.6 min | peak 8522 MB\n","step 22800 | lr 2.93e-04 | loss_ema 1.0544 | tokens 186,785,792 | 61.1 min | peak 8522 MB\n","step 23000 | lr 2.93e-04 | loss_ema 1.0529 | tokens 188,424,192 | 61.6 min | peak 8522 MB\n","step 23200 | lr 2.93e-04 | loss_ema 1.0362 | tokens 190,062,592 | 62.1 min | peak 8522 MB\n","step 23400 | lr 2.93e-04 | loss_ema 1.0143 | tokens 191,700,992 | 62.6 min | peak 8522 MB\n","step 23600 | lr 2.93e-04 | loss_ema 1.0476 | tokens 193,339,392 | 63.1 min | peak 8522 MB\n","step 23800 | lr 2.93e-04 | loss_ema 1.0592 | tokens 194,977,792 | 63.6 min | peak 8522 MB\n","step 24000 | lr 2.92e-04 | loss_ema 1.0246 | tokens 196,616,192 | 64.1 min | peak 8522 MB\n","âœ… eval @ step 24000: val_loss=2.2518 (best=2.2507)\n","step 24200 | lr 2.92e-04 | loss_ema 1.0293 | tokens 198,254,592 | 64.8 min | peak 8522 MB\n","step 24400 | lr 2.92e-04 | loss_ema 1.0429 | tokens 199,892,992 | 65.3 min | peak 8522 MB\n","step 24600 | lr 2.92e-04 | loss_ema 1.0512 | tokens 201,531,392 | 65.9 min | peak 8522 MB\n","step 24800 | lr 2.92e-04 | loss_ema 1.0068 | tokens 203,169,792 | 66.4 min | peak 8522 MB\n","step 25000 | lr 2.92e-04 | loss_ema 1.0442 | tokens 204,808,192 | 66.9 min | peak 8522 MB\n","step 25200 | lr 2.91e-04 | loss_ema 1.0502 | tokens 206,446,592 | 67.4 min | peak 8522 MB\n","step 25400 | lr 2.91e-04 | loss_ema 1.0233 | tokens 208,084,992 | 67.9 min | peak 8522 MB\n","step 25600 | lr 2.91e-04 | loss_ema 1.0090 | tokens 209,723,392 | 68.4 min | peak 8522 MB\n","step 25800 | lr 2.91e-04 | loss_ema 1.0537 | tokens 211,361,792 | 68.9 min | peak 8522 MB\n","step 26000 | lr 2.91e-04 | loss_ema 1.0174 | tokens 213,000,192 | 69.4 min | peak 8522 MB\n","âœ… eval @ step 26000: val_loss=2.2389 (best=2.2507)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 26200 | lr 2.91e-04 | loss_ema 1.0454 | tokens 214,638,592 | 70.1 min | peak 8522 MB\n","step 26400 | lr 2.90e-04 | loss_ema 1.0289 | tokens 216,276,992 | 70.6 min | peak 8522 MB\n","step 26600 | lr 2.90e-04 | loss_ema 1.0512 | tokens 217,915,392 | 71.1 min | peak 8522 MB\n","step 26800 | lr 2.90e-04 | loss_ema 1.0350 | tokens 219,553,792 | 71.6 min | peak 8522 MB\n","step 27000 | lr 2.90e-04 | loss_ema 1.0326 | tokens 221,192,192 | 72.1 min | peak 8522 MB\n","step 27200 | lr 2.90e-04 | loss_ema 1.0471 | tokens 222,830,592 | 72.6 min | peak 8522 MB\n","step 27400 | lr 2.90e-04 | loss_ema 1.0157 | tokens 224,468,992 | 73.1 min | peak 8522 MB\n","step 27600 | lr 2.89e-04 | loss_ema 0.9940 | tokens 226,107,392 | 73.6 min | peak 8522 MB\n","step 27800 | lr 2.89e-04 | loss_ema 1.0379 | tokens 227,745,792 | 74.2 min | peak 8522 MB\n","step 28000 | lr 2.89e-04 | loss_ema 1.0114 | tokens 229,384,192 | 74.7 min | peak 8522 MB\n","âœ… eval @ step 28000: val_loss=2.2247 (best=2.2389)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 28200 | lr 2.89e-04 | loss_ema 1.0075 | tokens 231,022,592 | 75.4 min | peak 8522 MB\n","step 28400 | lr 2.89e-04 | loss_ema 1.0293 | tokens 232,660,992 | 75.9 min | peak 8522 MB\n","step 28600 | lr 2.88e-04 | loss_ema 1.0169 | tokens 234,299,392 | 76.4 min | peak 8522 MB\n","step 28800 | lr 2.88e-04 | loss_ema 1.0239 | tokens 235,937,792 | 77.0 min | peak 8522 MB\n","step 29000 | lr 2.88e-04 | loss_ema 0.9957 | tokens 237,576,192 | 77.5 min | peak 8522 MB\n","step 29200 | lr 2.88e-04 | loss_ema 1.0453 | tokens 239,214,592 | 78.0 min | peak 8522 MB\n","step 29400 | lr 2.88e-04 | loss_ema 1.0013 | tokens 240,852,992 | 78.5 min | peak 8522 MB\n","step 29600 | lr 2.88e-04 | loss_ema 1.0149 | tokens 242,491,392 | 79.0 min | peak 8522 MB\n","step 29800 | lr 2.87e-04 | loss_ema 1.0247 | tokens 244,129,792 | 79.5 min | peak 8522 MB\n","step 30000 | lr 2.87e-04 | loss_ema 1.0008 | tokens 245,768,192 | 80.0 min | peak 8522 MB\n","âœ… eval @ step 30000: val_loss=2.2322 (best=2.2247)\n","step 30200 | lr 2.87e-04 | loss_ema 1.0184 | tokens 247,406,592 | 80.7 min | peak 8522 MB\n","step 30400 | lr 2.87e-04 | loss_ema 1.0028 | tokens 249,044,992 | 81.2 min | peak 8522 MB\n","step 30600 | lr 2.87e-04 | loss_ema 1.0129 | tokens 250,683,392 | 81.7 min | peak 8522 MB\n","step 30800 | lr 2.86e-04 | loss_ema 0.9832 | tokens 252,321,792 | 82.2 min | peak 8522 MB\n","step 31000 | lr 2.86e-04 | loss_ema 1.0249 | tokens 253,960,192 | 82.7 min | peak 8522 MB\n","step 31200 | lr 2.86e-04 | loss_ema 1.0203 | tokens 255,598,592 | 83.2 min | peak 8522 MB\n","step 31400 | lr 2.86e-04 | loss_ema 1.0116 | tokens 257,236,992 | 83.7 min | peak 8522 MB\n","step 31600 | lr 2.86e-04 | loss_ema 1.0371 | tokens 258,875,392 | 84.2 min | peak 8522 MB\n","step 31800 | lr 2.85e-04 | loss_ema 1.0342 | tokens 260,513,792 | 84.7 min | peak 8522 MB\n","step 32000 | lr 2.85e-04 | loss_ema 1.0424 | tokens 262,152,192 | 85.2 min | peak 8522 MB\n","âœ… eval @ step 32000: val_loss=2.2415 (best=2.2247)\n","step 32200 | lr 2.85e-04 | loss_ema 1.0260 | tokens 263,790,592 | 85.9 min | peak 8522 MB\n","step 32400 | lr 2.85e-04 | loss_ema 1.0139 | tokens 265,428,992 | 86.4 min | peak 8522 MB\n","step 32600 | lr 2.85e-04 | loss_ema 1.0250 | tokens 267,067,392 | 86.9 min | peak 8522 MB\n","step 32800 | lr 2.84e-04 | loss_ema 0.9754 | tokens 268,705,792 | 87.4 min | peak 8522 MB\n","step 33000 | lr 2.84e-04 | loss_ema 1.0273 | tokens 270,344,192 | 87.9 min | peak 8522 MB\n","step 33200 | lr 2.84e-04 | loss_ema 1.0215 | tokens 271,982,592 | 88.4 min | peak 8522 MB\n","step 33400 | lr 2.84e-04 | loss_ema 0.9865 | tokens 273,620,992 | 88.9 min | peak 8522 MB\n","step 33600 | lr 2.83e-04 | loss_ema 1.0052 | tokens 275,259,392 | 89.4 min | peak 8522 MB\n","step 33800 | lr 2.83e-04 | loss_ema 1.0241 | tokens 276,897,792 | 89.9 min | peak 8522 MB\n","step 34000 | lr 2.83e-04 | loss_ema 0.9994 | tokens 278,536,192 | 90.5 min | peak 8522 MB\n","âœ… eval @ step 34000: val_loss=2.2300 (best=2.2247)\n","step 34200 | lr 2.83e-04 | loss_ema 1.0023 | tokens 280,174,592 | 91.1 min | peak 8522 MB\n","step 34400 | lr 2.83e-04 | loss_ema 0.9906 | tokens 281,812,992 | 91.6 min | peak 8522 MB\n","step 34600 | lr 2.82e-04 | loss_ema 1.0283 | tokens 283,451,392 | 92.1 min | peak 8522 MB\n","step 34800 | lr 2.82e-04 | loss_ema 0.9871 | tokens 285,089,792 | 92.6 min | peak 8522 MB\n","step 35000 | lr 2.82e-04 | loss_ema 0.9719 | tokens 286,728,192 | 93.1 min | peak 8522 MB\n","step 35200 | lr 2.82e-04 | loss_ema 1.0092 | tokens 288,366,592 | 93.6 min | peak 8522 MB\n","step 35400 | lr 2.81e-04 | loss_ema 1.0078 | tokens 290,004,992 | 94.1 min | peak 8522 MB\n","step 35600 | lr 2.81e-04 | loss_ema 0.9912 | tokens 291,643,392 | 94.6 min | peak 8522 MB\n","step 35800 | lr 2.81e-04 | loss_ema 1.0277 | tokens 293,281,792 | 95.1 min | peak 8522 MB\n","step 36000 | lr 2.81e-04 | loss_ema 1.0125 | tokens 294,920,192 | 95.7 min | peak 8522 MB\n","âœ… eval @ step 36000: val_loss=2.2236 (best=2.2247)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 36200 | lr 2.80e-04 | loss_ema 1.0021 | tokens 296,558,592 | 96.5 min | peak 8522 MB\n","step 36400 | lr 2.80e-04 | loss_ema 0.9893 | tokens 298,196,992 | 97.0 min | peak 8522 MB\n","step 36600 | lr 2.80e-04 | loss_ema 1.0133 | tokens 299,835,392 | 97.5 min | peak 8522 MB\n","step 36800 | lr 2.80e-04 | loss_ema 1.0052 | tokens 301,473,792 | 98.0 min | peak 8522 MB\n","step 37000 | lr 2.80e-04 | loss_ema 1.0198 | tokens 303,112,192 | 98.5 min | peak 8522 MB\n","step 37200 | lr 2.79e-04 | loss_ema 1.0324 | tokens 304,750,592 | 99.0 min | peak 8522 MB\n","step 37400 | lr 2.79e-04 | loss_ema 0.9974 | tokens 306,388,992 | 99.5 min | peak 8522 MB\n","step 37600 | lr 2.79e-04 | loss_ema 1.0221 | tokens 308,027,392 | 100.0 min | peak 8522 MB\n","step 37800 | lr 2.79e-04 | loss_ema 1.0019 | tokens 309,665,792 | 100.5 min | peak 8522 MB\n","step 38000 | lr 2.78e-04 | loss_ema 1.0067 | tokens 311,304,192 | 101.0 min | peak 8522 MB\n","âœ… eval @ step 38000: val_loss=2.2226 (best=2.2236)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 38200 | lr 2.78e-04 | loss_ema 0.9746 | tokens 312,942,592 | 101.7 min | peak 8522 MB\n","step 38400 | lr 2.78e-04 | loss_ema 0.9852 | tokens 314,580,992 | 102.2 min | peak 8522 MB\n","step 38600 | lr 2.78e-04 | loss_ema 0.9900 | tokens 316,219,392 | 102.8 min | peak 8522 MB\n","step 38800 | lr 2.77e-04 | loss_ema 1.0100 | tokens 317,857,792 | 103.3 min | peak 8522 MB\n","step 39000 | lr 2.77e-04 | loss_ema 1.0231 | tokens 319,496,192 | 103.8 min | peak 8522 MB\n","step 39200 | lr 2.77e-04 | loss_ema 1.0244 | tokens 321,134,592 | 104.3 min | peak 8522 MB\n","step 39400 | lr 2.76e-04 | loss_ema 0.9837 | tokens 322,772,992 | 104.8 min | peak 8522 MB\n","step 39600 | lr 2.76e-04 | loss_ema 1.0044 | tokens 324,411,392 | 105.3 min | peak 8522 MB\n","step 39800 | lr 2.76e-04 | loss_ema 0.9987 | tokens 326,049,792 | 105.8 min | peak 8522 MB\n","step 40000 | lr 2.76e-04 | loss_ema 1.0124 | tokens 327,688,192 | 106.3 min | peak 8522 MB\n","âœ… eval @ step 40000: val_loss=2.2062 (best=2.2226)\n","ðŸ† New best saved to: /content/drive/MyDrive/best_model_part4/best_transformer.pt\n","step 40200 | lr 2.75e-04 | loss_ema 1.0147 | tokens 329,326,592 | 107.1 min | peak 8522 MB\n","step 40400 | lr 2.75e-04 | loss_ema 1.0105 | tokens 330,964,992 | 107.6 min | peak 8522 MB\n","step 40600 | lr 2.75e-04 | loss_ema 1.0096 | tokens 332,603,392 | 108.1 min | peak 8522 MB\n","step 40800 | lr 2.75e-04 | loss_ema 1.0165 | tokens 334,241,792 | 108.6 min | peak 8522 MB\n","step 41000 | lr 2.74e-04 | loss_ema 1.0017 | tokens 335,880,192 | 109.1 min | peak 8522 MB\n","step 41200 | lr 2.74e-04 | loss_ema 0.9838 | tokens 337,518,592 | 109.6 min | peak 8522 MB\n","step 41400 | lr 2.74e-04 | loss_ema 1.0078 | tokens 339,156,992 | 110.1 min | peak 8522 MB\n","step 41600 | lr 2.74e-04 | loss_ema 0.9894 | tokens 340,795,392 | 110.6 min | peak 8522 MB\n","step 41800 | lr 2.73e-04 | loss_ema 0.9724 | tokens 342,433,792 | 111.1 min | peak 8522 MB\n","step 42000 | lr 2.73e-04 | loss_ema 0.9928 | tokens 344,072,192 | 111.6 min | peak 8522 MB\n","âœ… eval @ step 42000: val_loss=2.2097 (best=2.2062)\n","step 42200 | lr 2.73e-04 | loss_ema 1.0277 | tokens 345,710,592 | 112.3 min | peak 8522 MB\n","step 42400 | lr 2.72e-04 | loss_ema 0.9867 | tokens 347,348,992 | 112.8 min | peak 8522 MB\n","step 42600 | lr 2.72e-04 | loss_ema 0.9701 | tokens 348,987,392 | 113.3 min | peak 8522 MB\n","step 42800 | lr 2.72e-04 | loss_ema 0.9811 | tokens 350,625,792 | 113.8 min | peak 8522 MB\n","step 43000 | lr 2.72e-04 | loss_ema 1.0232 | tokens 352,264,192 | 114.3 min | peak 8522 MB\n","step 43200 | lr 2.71e-04 | loss_ema 1.0125 | tokens 353,902,592 | 114.8 min | peak 8522 MB\n","step 43400 | lr 2.71e-04 | loss_ema 0.9736 | tokens 355,540,992 | 115.3 min | peak 8522 MB\n","step 43600 | lr 2.71e-04 | loss_ema 0.9897 | tokens 357,179,392 | 115.8 min | peak 8522 MB\n","step 43800 | lr 2.70e-04 | loss_ema 0.9768 | tokens 358,817,792 | 116.3 min | peak 8522 MB\n","step 44000 | lr 2.70e-04 | loss_ema 1.0112 | tokens 360,456,192 | 116.8 min | peak 8522 MB\n","âœ… eval @ step 44000: val_loss=2.2296 (best=2.2062)\n","step 44200 | lr 2.70e-04 | loss_ema 0.9907 | tokens 362,094,592 | 117.5 min | peak 8522 MB\n","step 44400 | lr 2.70e-04 | loss_ema 0.9930 | tokens 363,732,992 | 118.0 min | peak 8522 MB\n","step 44600 | lr 2.69e-04 | loss_ema 1.0023 | tokens 365,371,392 | 118.5 min | peak 8522 MB\n","step 44800 | lr 2.69e-04 | loss_ema 0.9669 | tokens 367,009,792 | 119.0 min | peak 8522 MB\n","step 45000 | lr 2.69e-04 | loss_ema 1.0027 | tokens 368,648,192 | 119.5 min | peak 8522 MB\n","step 45200 | lr 2.68e-04 | loss_ema 0.9722 | tokens 370,286,592 | 120.0 min | peak 8522 MB\n","Finished. Saved last checkpoint to: /content/drive/MyDrive/best_model_part4/last.pt\n","Training stats: {'step': 45201, 'tokens_seen': 370286592, 'best_val': 2.206218101978302, 'peak_mem_MB': 8522.38037109375, 'best_ckpt': '/content/drive/MyDrive/best_model_part4/best_transformer.pt', 'last_ckpt': '/content/drive/MyDrive/best_model_part4/last.pt'}\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def encode_notes(notes):\n","    \"\"\"\n","    notes: list of ABC note tokens, e.g. [\"C\", \"E\", \"G\"]\n","    \"\"\"\n","    return torch.tensor(\n","        [[token_to_id.get(n, token_to_id[\"<UNK>\"]) for n in notes]],\n","        dtype=torch.long\n","    ).to(device)\n","\n","\n","def decode_notes(ids):\n","    \"\"\"\n","    ids: list of token IDs\n","    \"\"\"\n","    return \" \".join(id_to_token[i] for i in ids if i in id_to_token)\n"],"metadata":{"id":"KVWqbiitGsC1","executionInfo":{"status":"ok","timestamp":1765854076452,"user_tz":300,"elapsed":40,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate_notes(\n","    model,\n","    start_ids,\n","    max_new_tokens=600,\n","    temperature=0.9,\n","    top_k=40\n","):\n","    model.eval()\n","    out = start_ids.clone()\n","\n","    for _ in range(max_new_tokens):\n","        idx = out[:, -model.block_size:]\n","        logits, _ = model(idx)\n","\n","        logits = logits[:, -1, :] / temperature\n","\n","        if top_k is not None:\n","            v, _ = torch.topk(logits, top_k)\n","            logits[logits < v[:, [-1]]] = -float(\"inf\")\n","\n","        probs = torch.softmax(logits, dim=-1)\n","        next_id = torch.multinomial(probs, 1)\n","\n","        out = torch.cat([out, next_id], dim=1)\n","\n","    return out\n"],"metadata":{"id":"I9b8-7CWGuKM","executionInfo":{"status":"ok","timestamp":1765854083016,"user_tz":300,"elapsed":5,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["def postprocess_notes(note_str, max_consecutive_rests=2):\n","    \"\"\"\n","    Limits excessive 'z' rest tokens that cause long silence.\n","    \"\"\"\n","    tokens = note_str.split()\n","    cleaned = []\n","    rest_count = 0\n","\n","    for t in tokens:\n","        if t.startswith(\"z\"):\n","            rest_count += 1\n","            if rest_count <= max_consecutive_rests:\n","                cleaned.append(\"z\")\n","        else:\n","            rest_count = 0\n","            cleaned.append(t)\n","\n","    return \" \".join(cleaned)\n"],"metadata":{"id":"P2see1pzGv21","executionInfo":{"status":"ok","timestamp":1765854091689,"user_tz":300,"elapsed":43,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["ABC_HEADER = \"\"\"X:1\n","T:Generated Sample\n","M:4/4\n","L:1/8\n","Q:1/4=120\n","K:C\n","\"\"\"\n"],"metadata":{"id":"8DN1oiGXGxyY","executionInfo":{"status":"ok","timestamp":1765854098877,"user_tz":300,"elapsed":5,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","ABC_OUT = \"/content/drive/MyDrive/generated_abc\"\n","os.makedirs(ABC_OUT, exist_ok=True)\n","\n","\n","start_uncond = encode_notes([\"C\"])\n","\n","for i in range(5):\n","    out = generate_notes(\n","        model,\n","        start_uncond,\n","        max_new_tokens=600,\n","        temperature=0.9,\n","        top_k=40\n","    )\n","\n","    notes = decode_notes(out[0].cpu().tolist())\n","    body = postprocess_notes(notes)\n","\n","    abc = ABC_HEADER + body + \"\\n\"\n","    with open(f\"{ABC_OUT}/unconditional_{i}.abc\", \"w\") as f:\n","        f.write(abc)\n","\n","print(\"âœ… 5 unconditional samples generated\")\n","\n","\n","\n","prefix = encode_notes([\"C\", \"E\", \"G\"])\n","\n","for i in range(5):\n","    out = generate_notes(\n","        model,\n","        prefix,\n","        max_new_tokens=600,\n","        temperature=0.9,\n","        top_k=40\n","    )\n","\n","    notes = decode_notes(out[0].cpu().tolist())\n","    body = postprocess_notes(notes)\n","\n","    abc = ABC_HEADER + body + \"\\n\"\n","    with open(f\"{ABC_OUT}/conditional_{i}.abc\", \"w\") as f:\n","        f.write(abc)\n","\n","print(\"âœ… 5 conditional samples generated\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQiszDsDGzhS","executionInfo":{"status":"ok","timestamp":1765854191152,"user_tz":300,"elapsed":84465,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"41fbe6b3-1e08-4e6a-f4d6-22b63671ee92"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… 5 unconditional samples generated\n","âœ… 5 conditional samples generated\n"]}]},{"cell_type":"code","source":["from music21 import converter, stream\n","\n","MIDI_OUT = \"/content/drive/MyDrive/generated_midi\"\n","os.makedirs(MIDI_OUT, exist_ok=True)\n","\n","converted, failed = 0, 0\n","\n","for file in os.listdir(ABC_OUT):\n","    if not file.endswith(\".abc\"):\n","        continue\n","\n","    abc_path = os.path.join(ABC_OUT, file)\n","    midi_path = os.path.join(MIDI_OUT, file.replace(\".abc\", \".mid\"))\n","\n","    try:\n","        score = converter.parse(abc_path)\n","\n","\n","        flat = score.flatten()\n","        s = stream.Score()\n","        s.insert(0, flat)\n","\n","        s.write(\"midi\", midi_path)\n","        converted += 1\n","    except Exception as e:\n","        print(\"âŒ Failed:\", file, e)\n","        failed += 1\n","\n","print(f\"\\nâœ… MIDI conversion complete\")\n","print(f\"Converted: {converted}\")\n","print(f\"Failed   : {failed}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6c7X5FDG1vG","executionInfo":{"status":"ok","timestamp":1765854197295,"user_tz":300,"elapsed":1993,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"bfd35fa8-57fc-4b0d-e0fe-0afeea46e725"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","âœ… MIDI conversion complete\n","Converted: 10\n","Failed   : 0\n"]}]},{"cell_type":"code","source":["block_size = 256\n","\n","test_data = BinDataset(TEST_BIN, block_size)\n","\n","print(\"Total test tokens:\", len(test_data.data))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dd_EQJgZLghH","executionInfo":{"status":"ok","timestamp":1765855423187,"user_tz":300,"elapsed":18,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"17ab398f-a6be-49a5-d7fc-5ccb4b0cbdf1"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Total test tokens: 1426554\n"]}]},{"cell_type":"code","source":["import math\n","import torch\n","\n","@torch.no_grad()\n","def evaluate_perplexity(model, test_data, batch_size=8, iters=500):\n","    model.eval()\n","    losses = []\n","\n","    for _ in range(iters):\n","        xb, yb = test_data.get_batch(batch_size, device)\n","        _, loss = model(xb, yb)\n","        losses.append(loss.item())\n","\n","    avg_loss = sum(losses) / len(losses)\n","    perplexity = math.exp(avg_loss)\n","    return avg_loss, perplexity\n","\n","\n","test_loss, test_ppl = evaluate_perplexity(\n","    model,\n","    test_data,\n","    batch_size=8,\n","    iters=500\n",")\n","\n","print(f\"Final Test Loss: {test_loss:.4f}\")\n","print(f\"Final Test Perplexity: {test_ppl:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epXpxYPAL3HA","executionInfo":{"status":"ok","timestamp":1765855451305,"user_tz":300,"elapsed":18763,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"b2fbeec2-2cca-46ad-bb12-5947b24983bc"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Test Loss: 2.2192\n","Final Test Perplexity: 9.20\n"]}]},{"cell_type":"code","source":["from music21 import converter\n","import tempfile\n","import os\n","\n","def is_valid_abc(abc_text, min_tokens=20):\n","    tokens = abc_text.strip().split()\n","    if len(tokens) < min_tokens:\n","        return False\n","\n","    try:\n","        with tempfile.NamedTemporaryFile(\"w\", suffix=\".abc\", delete=False) as f:\n","            f.write(abc_text)\n","            temp_path = f.name\n","\n","        converter.parse(temp_path)\n","        return True\n","    except Exception:\n","        return False\n","    finally:\n","        if os.path.exists(temp_path):\n","            os.remove(temp_path)\n"],"metadata":{"id":"01pSCR0rL5K5","executionInfo":{"status":"ok","timestamp":1765855493872,"user_tz":300,"elapsed":12,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["ABC_OUT = \"/content/drive/MyDrive/generated_abc\"\n","\n","valid = 0\n","total = 0\n","\n","for file in os.listdir(ABC_OUT):\n","    if not file.endswith(\".abc\"):\n","        continue\n","\n","    total += 1\n","    with open(os.path.join(ABC_OUT, file)) as f:\n","        abc = f.read()\n","\n","    if is_valid_abc(abc):\n","        valid += 1\n","\n","valid_pct = 100 * valid / total\n","\n","print(f\"Syntactically valid ABC files: {valid}/{total}\")\n","print(f\"Percentage valid: {valid_pct:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzGTTHalMIXl","executionInfo":{"status":"ok","timestamp":1765855562923,"user_tz":300,"elapsed":1154,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"b7c7eae6-36b9-4f27-b0e9-6f345ff07222"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Syntactically valid ABC files: 10/10\n","Percentage valid: 100.00%\n"]}]},{"cell_type":"code","source":["from music21 import converter\n","\n","MIDI_OUT = \"/content/drive/MyDrive/generated_midi\"\n","os.makedirs(MIDI_OUT, exist_ok=True)\n","\n","converted = 0\n","failed = 0\n","\n","for file in os.listdir(ABC_OUT):\n","    if not file.endswith(\".abc\"):\n","        continue\n","\n","    abc_path = os.path.join(ABC_OUT, file)\n","    midi_path = os.path.join(MIDI_OUT, file.replace(\".abc\", \".mid\"))\n","\n","    try:\n","        score = converter.parse(abc_path)\n","        score.write(\"midi\", midi_path)\n","        converted += 1\n","    except Exception:\n","        failed += 1\n","\n","total = converted + failed\n","midi_pct = 100 * converted / total\n","\n","print(f\"MIDI conversion success: {converted}/{total}\")\n","print(f\"Conversion success rate: {midi_pct:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8XDNpGjMZjC","executionInfo":{"status":"ok","timestamp":1765855581458,"user_tz":300,"elapsed":1573,"user":{"displayName":"Gurjeet Kaur","userId":"13444970897322380187"}},"outputId":"19fff6c8-f016-44af-920a-f81c90044b31"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["MIDI conversion success: 10/10\n","Conversion success rate: 100.00%\n"]}]}]}