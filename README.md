# Scaling Laws in Symbolic Music Modeling

This repository contains the code for a course project studying scaling laws in
symbolic music generation. The project compares decoder-only Transformer models
with RNN (LSTM) baselines using symbolic music represented in ABC notation.

The objective is to analyze how validation loss scales with increasing model
size and to compare architectural efficiency, training cost, and sample quality
between Transformers and RNNs.

---

## Files in This Repository

All files are provided directly in the repository root for simplicity.

- **tokenization.ipynb**  
  Performs full data preprocessing and tokenization, including:
  - MIDI to ABC conversion  
  - Cleaning and filtering of ABC files  
  - Chunking long sequences  
  - Note-level vocabulary construction  
  - Train/validation/test split generation  

- **transformer.ipynb**  
  Trains a family of decoder-only Transformer language models of varying sizes
  (Tiny to XL) using a nanoGPT-style implementation. Models are trained for
  exactly one epoch to study scaling behavior.

- **rnn.ipynb**  
  Trains LSTM-based RNN baseline models matched in parameter count to the
  Transformer models. Uses the same dataset, tokenization, and training setup
  for fair comparison.

- **best_model.ipynb**  
  Trains the best-performing Transformer model using a fixed time budget.
  Includes checkpointing, validation-based model selection, final test
  evaluation, perplexity computation, and qualitative music sample generation
  (ABC and MIDI).

- **comparison.ipynb**  
  Compares Transformer and RNN models by:
  - Validation loss vs. model size  
  - Power-law scaling fits  
  - Training time efficiency  
  - Memory efficiency  
  - Sample efficiency analysis  

---

## Model Configurations

Transformer models were trained across multiple sizes using consistent training
settings. Key configurations are summarized below.

| Model | Layers | Heads | Embedding Dim | Params (M) |
|------:|:------:|:-----:|:-------------:|-----------:|
| Tiny  | 6      | 6     | 192           | ~3.4       |
| Small | 8      | 8     | 256           | ~7–8       |
| Medium| 12     | 12    | 384           | ~20–22     |
| Large | 16     | 16    | 512           | ~50        |
| XL    | 20     | 20    | 640           | ~100.8     |

Exact model definitions and hyperparameters are specified inside the notebooks.

---

## Data and Files

The notebooks use absolute file paths (local machine and Google Colab) that were
used during the original experiments.

Due to the large size of the dataset, the following files are not included in
this repository:

- Raw MIDI files  
- Preprocessed ABC files  
- Tokenized text files  
- Binary `.bin` files  
- Model checkpoints  
- Generated MIDI files  

### Data Source

The experiments use the **Lakh MIDI Dataset (LMD)**:  
https://colinraffel.com/projects/lmd/

### Reproducing the Experiments

To reproduce the experiments:

1. Download the Lakh MIDI Dataset  
2. Update directory paths in `tokenization.ipynb`  
3. Run preprocessing and tokenization  
4. Generate `.bin` files  
5. Run the training and evaluation notebooks  

All preprocessing, training, evaluation, and generation logic is fully
provided in this repository.

---

## Key Results

- Transformer models exhibit clear power-law scaling of validation loss with
  increasing model size after one epoch of training.
- The best Transformer model (≈100.8M parameters) achieved:
  - Test Loss ≈ 2.22  
  - Test Perplexity ≈ 9.20
- Transformers scale more favorably than RNNs in terms of sample efficiency,
  at the cost of higher computation and memory usage.

Detailed plots and analyses are available in the notebooks.

---

## Audio Samples

Audio samples generated by the best-performing Transformer model are available
for qualitative evaluation at the link below:

https://github.com/gurjeetkaur0005/music_scaling_laws/tree/main/samples

---

## Notes

- Model configurations are defined directly inside the notebooks  
- Large files are intentionally excluded due to GitHub size limits  
- This repository is intended for academic coursework and reproducibility  

